#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# File  : iptvPro.py
# Author: DaShenHan&é“é•¿-----å…ˆè‹¦åç”œï¼Œä»»å‡­æ™šé£æ‹‚æŸ³é¢œ------
# Date  : 2024/10/16
# desc åˆ©ç”¨playwrightå®ç°

import json
import time
from datetime import datetime
import concurrent.futures
from pathlib import Path
import requests
import re
import os
import threading
from queue import Queue
import asyncio
from playwright.async_api import async_playwright

semaphore = asyncio.Semaphore(3)

import eventlet

eventlet.monkey_patch()

today = datetime.now()
formatted_date = today.strftime('%Yå¹´%mæœˆ%dæ—¥')[2:]

config_path = Path(os.path.abspath(os.path.join(os.path.dirname(__file__), './quart_config.json'))).as_posix()
print(config_path)
if not os.path.exists(config_path):
    exit(f"config_path not found for {config_path}")

with open(config_path, encoding='utf-8') as f:
    config_dict = json.loads(f.read())
print(config_dict)
save_path = Path(os.path.abspath(os.path.join(os.path.dirname(__file__), './static/lives'))).as_posix()
if not os.path.exists(save_path):
    os.makedirs(save_path, exist_ok=True)
print('save_path:', save_path)
t1 = time.time()

urls = [
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E5%B9%BF%E8%A5%BF%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E5%B9%BF%E4%B8%9C%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E9%99%95%E8%A5%BF%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E6%B9%96%E5%8D%97%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E5%B1%B1%E8%A5%BF%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E6%B9%96%E5%8C%97%22',
    'https://www.zoomeye.org/searchResult?q=/iptv/live/zh_cn.js%20%2Bcountry%3A%22CN%22%20%2Bsubdivisions%3A%22%E6%B2%B3%E5%8C%97%22'
]

replace_dict1 = {
    "cctv": "CCTV",
    "ä¸­å¤®": "CCTV",
    "å¤®è§†": "CCTV",
    "é«˜æ¸…": "",
    "è¶…é«˜": "",
    "HD": "",
    "æ ‡æ¸…": "",
    "é¢‘é“": "",
    "-": "",
    " ": "",
    "PLUS": "+",
    "ï¼‹": "+",
    "(": "",
    ")": "",
}

replace_dict2 = {
    "CCTV1ç»¼åˆ": "CCTV1",
    "CCTV2è´¢ç»": "CCTV2",
    "CCTV3ç»¼è‰º": "CCTV3",
    "CCTV4å›½é™…": "CCTV4",
    "CCTV4ä¸­æ–‡å›½é™…": "CCTV4",
    "CCTV4æ¬§æ´²": "CCTV4",
    "CCTV5ä½“è‚²": "CCTV5",
    "CCTV6ç”µå½±": "CCTV6",
    "CCTV7å†›äº‹": "CCTV7",
    "CCTV7å†›å†œ": "CCTV7",
    "CCTV7å†œä¸š": "CCTV7",
    "CCTV7å›½é˜²å†›äº‹": "CCTV7",
    "CCTV8ç”µè§†å‰§": "CCTV8",
    "CCTV9è®°å½•": "CCTV9",
    "CCTV9çºªå½•": "CCTV9",
    "CCTV10ç§‘æ•™": "CCTV10",
    "CCTV11æˆæ›²": "CCTV11",
    "CCTV12ç¤¾ä¼šä¸æ³•": "CCTV12",
    "CCTV13æ–°é—»": "CCTV13",
    "CCTVæ–°é—»": "CCTV13",
    "CCTV14å°‘å„¿": "CCTV14",
    "CCTV15éŸ³ä¹": "CCTV15",
    "CCTV16å¥¥æ—åŒ¹å…‹": "CCTV16",
    "CCTV17å†œä¸šå†œæ‘": "CCTV17",
    "CCTV17å†œä¸š": "CCTV17",
    "CCTV5+ä½“è‚²èµ›è§†": "CCTV5+",
    "CCTV5+ä½“è‚²èµ›äº‹": "CCTV5+",
    "CCTV5+ä½“è‚²": "CCTV5+",
}

# çº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºå­˜å‚¨ä¸‹è½½ä»»åŠ¡
task_queue = Queue()
# çº¿ç¨‹å®‰å…¨çš„åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨ç»“æœ
results = []

channels = []
error_channels = []


async def _on_dialog(dialog):
    """
    å…¨å±€å¼¹çª—æ‹¦æˆªå™¨
    @param dialog:
    @return:
    """
    print('_on_dialog:', dialog)
    await dialog.accept()


async def _on_pageerror(error):
    """
    å…¨å±€é¡µé¢è¯·æ±‚é”™è¯¯æ‹¦æˆªå™¨
    @param error:
    @return:
    """
    print('_on_pageerror:', error)
    pass


async def _on_crash(*args):
    print(f"_on_crash:Page has crashed! {len(args)}")
    # await page.close()  # å…³é—­é¡µé¢æˆ–é‡‡å–å…¶ä»–æªæ–½


# å¼‚æ­¥è·å–é¡µé¢æºç 
async def get_page_source(url, timeout, channel, headless):
    async with semaphore:  # åœ¨ä»»åŠ¡å¼€å§‹å‰è·å–ä¿¡å·é‡
        # æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹ç®¡ç† Playwright å®ä¾‹
        async with async_playwright() as p:
            browser = await p.chromium.launch(channel=channel, headless=headless)  # å¯åŠ¨æµè§ˆå™¨
            context = await browser.new_context()  # åˆ›å»ºæ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡
            page = await context.new_page()  # åˆ›å»ºæ–°é¡µé¢
            # æ‰“å¼€å¼¹çª—æ‹¦æˆªå™¨
            page.on("dialog", _on_dialog)
            # æ‰“å¼€é¡µé¢é”™è¯¯ç›‘å¬
            page.on("pageerror", _on_pageerror)
            # æ‰“å¼€é¡µé¢å´©æºƒç›‘å¬
            page.on("crash", _on_crash)

            print('goto:', url)
            try:
                await page.goto(url)  # æ‰“å¼€æŒ‡å®šç½‘å€
                await page.wait_for_timeout(timeout)
                content = await page.content()  # è·å–é¡µé¢æ¸²æŸ“åçš„æºç 
            except Exception as e:
                print(f'get_page_source error:{e}')
                content = ''
            await context.close()  # å…³é—­ä¸Šä¸‹æ–‡
            await browser.close()  # å…³é—­æµè§ˆå™¨
        return content


# å¼‚æ­¥è¿è¡Œå¤šä¸ªä»»åŠ¡
async def open_browser_and_run_tasks(urls, timeout, channel, headless):
    tasks = [get_page_source(url, timeout, channel, headless) for url in urls]  # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    # ä½¿ç”¨ gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡
    _results = await asyncio.gather(*tasks)
    return _results


def get_page_content_multi(urls, timeout=10000, channel='chrome', headless=False):
    # å®šä¹‰ä¸€ä¸ªä¿¡å·é‡ï¼Œé™åˆ¶æœ€å¤šåŒæ—¶è¿è¡Œ20ä¸ªä»»åŠ¡

    loop = asyncio.get_event_loop()
    page_sources = loop.run_until_complete(open_browser_and_run_tasks(urls, timeout, channel, headless))
    return page_sources


def get_replace_name(_name):
    # åˆ é™¤ç‰¹å®šæ–‡å­—
    for _key, _value in replace_dict1.items():
        _name = _name.replace(_key, _value)
    _name = re.sub(r"CCTV(\d+)å°", r"CCTV\1", _name)
    for _key, _value in replace_dict2.items():
        _name = _name.replace(_key, _value)
    return _name


def modify_urls(url):
    modified_urls = []
    ip_start_index = url.find("//") + 2
    ip_end_index = url.find(":", ip_start_index)
    base_url = url[:ip_start_index]  # http:// or https://
    ip_address = url[ip_start_index:ip_end_index]
    port = url[ip_end_index:]
    ip_end = "/iptv/live/1000.json?key=txiptv"
    for i in range(1, 256):
        modified_ip = f"{ip_address[:-1]}{i}"
        modified_url = f"{base_url}{modified_ip}{port}{ip_end}"
        modified_urls.append(modified_url)

    return modified_urls


def is_url_accessible(url):
    try:
        response = requests.get(url, timeout=0.5)
        if response.status_code == 200:
            return url
    except requests.exceptions.RequestException:
        pass
    return None


# å®šä¹‰å·¥ä½œçº¿ç¨‹å‡½æ•°
def worker():
    while True:
        # ä»é˜Ÿåˆ—ä¸­è·å–ä¸€ä¸ªä»»åŠ¡
        channel_name, channel_url = task_queue.get()
        try:
            channel_url_t = channel_url.rstrip(channel_url.split('/')[-1])  # m3u8é“¾æ¥å‰ç¼€
            lines = requests.get(channel_url, timeout=1).text.strip().split('\n')  # è·å–m3u8æ–‡ä»¶å†…å®¹
            ts_lists = [line.split('/')[-1] for line in lines if line.startswith('#') == False]  # è·å–m3u8æ–‡ä»¶ä¸‹è§†é¢‘æµåç¼€
            ts_lists_0 = ts_lists[0].rstrip(ts_lists[0].split('.ts')[-1])  # m3u8é“¾æ¥å‰ç¼€
            ts_url = channel_url_t + ts_lists[0]  # æ‹¼æ¥å•ä¸ªè§†é¢‘ç‰‡æ®µä¸‹è½½é“¾æ¥

            # å¤šè·å–çš„è§†é¢‘æ•°æ®è¿›è¡Œ5ç§’é’Ÿé™åˆ¶
            with eventlet.Timeout(5, False):
                start_time = time.time()
                content = requests.get(ts_url, timeout=1).content
                end_time = time.time()
                response_time = (end_time - start_time) * 1

            if content:
                with open(ts_lists_0, 'ab') as f:
                    f.write(content)  # å†™å…¥æ–‡ä»¶
                file_size = len(content)
                # print(f"æ–‡ä»¶å¤§å°ï¼š{file_size} å­—èŠ‚")
                download_speed = file_size / response_time / 1024
                # print(f"ä¸‹è½½é€Ÿåº¦ï¼š{download_speed:.3f} kB/s")
                normalized_speed = min(max(download_speed / 1024, 0.001), 100)  # å°†é€Ÿç‡ä»kB/sè½¬æ¢ä¸ºMB/så¹¶é™åˆ¶åœ¨1~100ä¹‹é—´
                # print(f"æ ‡å‡†åŒ–åçš„é€Ÿç‡ï¼š{normalized_speed:.3f} MB/s")

                # åˆ é™¤ä¸‹è½½çš„æ–‡ä»¶
                os.remove(ts_lists_0)
                result = channel_name, channel_url, f"{normalized_speed:.3f} MB/s"
                results.append(result)
                numberx = (len(results) + len(error_channels)) / len(channels) * 100
                print(
                    f"å¯ç”¨é¢‘é“ï¼š{len(results)} ä¸ª , ä¸å¯ç”¨é¢‘é“ï¼š{len(error_channels)} ä¸ª , æ€»é¢‘é“ï¼š{len(channels)} ä¸ª ,æ€»è¿›åº¦ï¼š{numberx:.2f} %ã€‚")
        except:
            error_channel = channel_name, channel_url
            error_channels.append(error_channel)
            numberx = (len(results) + len(error_channels)) / len(channels) * 100
            print(
                f"å¯ç”¨é¢‘é“ï¼š{len(results)} ä¸ª , ä¸å¯ç”¨é¢‘é“ï¼š{len(error_channels)} ä¸ª , æ€»é¢‘é“ï¼š{len(channels)} ä¸ª ,æ€»è¿›åº¦ï¼š{numberx:.2f} %ã€‚")

        # æ ‡è®°ä»»åŠ¡å®Œæˆ
        task_queue.task_done()


def channel_key(channel_name):
    match = re.search(r'\d+', channel_name)
    if match:
        return int(match.group())
    else:
        return float('inf')  # è¿”å›ä¸€ä¸ªæ— ç©·å¤§çš„æ•°å­—ä½œä¸ºå…³é”®å­—


def main():
    _channel = 'chrome' if config_dict['USE_CHROME'] else None
    _headless = config_dict['SNIFFER_HEADLESS']
    page_sources = get_page_content_multi(urls, channel=_channel, headless=_headless)
    _results = []
    urls_count = len(urls)
    for index, url in enumerate(urls):
        print(f'get_page_content for {url} ({index + 1}/{urls_count})')
        page_content = page_sources[index]
        # print(len(page_content))
        # æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆæŒ‡å®šæ ¼å¼çš„ç½‘å€
        pattern = r"http://\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+"  # è®¾ç½®åŒ¹é…çš„æ ¼å¼ï¼Œå¦‚http://8.8.8.8:8888
        urls_all = re.findall(pattern, page_content)
        # urls = list(set(urls_all))  # å»é‡å¾—åˆ°å”¯ä¸€çš„URLåˆ—è¡¨
        urls_ret = set(urls_all)  # å»é‡å¾—åˆ°å”¯ä¸€çš„URLåˆ—è¡¨
        x_urls = []
        for url in urls_ret:  # å¯¹urlsè¿›è¡Œå¤„ç†ï¼Œipç¬¬å››ä½ä¿®æ”¹ä¸º1ï¼Œå¹¶å»é‡
            url = url.strip()
            ip_start_index = url.find("//") + 2
            ip_end_index = url.find(":", ip_start_index)
            ip_dot_start = url.find(".") + 1
            ip_dot_second = url.find(".", ip_dot_start) + 1
            ip_dot_three = url.find(".", ip_dot_second) + 1
            base_url = url[:ip_start_index]  # http:// or https://
            ip_address = url[ip_start_index:ip_dot_three]
            port = url[ip_end_index:]
            ip_end = "1"
            modified_ip = f"{ip_address}{ip_end}"
            x_url = f"{base_url}{modified_ip}{port}"
            x_urls.append(x_url)
        urls_ret = set(x_urls)  # å»é‡å¾—åˆ°å”¯ä¸€çš„URLåˆ—è¡¨
        print(len(urls_ret), urls_ret)
        if len(urls_ret) < 1:
            continue
        # max_workers = min(max(len(urls), 1), 100)
        max_workers = 100
        # print(f'max_workers:{max_workers}')
        valid_urls = []
        #   å¤šçº¿ç¨‹è·å–å¯ç”¨url
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for url in urls_ret:
                url = url.strip()
                modified_urls = modify_urls(url)
                # print(f'modified_urls:{modified_urls}')
                for modified_url in modified_urls:
                    futures.append(executor.submit(is_url_accessible, modified_url))

            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    valid_urls.append(result)

        for url in valid_urls:
            print(url)
        # éå†ç½‘å€åˆ—è¡¨ï¼Œè·å–JSONæ–‡ä»¶å¹¶è§£æ
        for url in valid_urls:
            try:
                # å‘é€GETè¯·æ±‚è·å–JSONæ–‡ä»¶ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´ä¸º0.5ç§’
                ip_start_index = url.find("//") + 2
                ip_dot_start = url.find(".") + 1
                ip_index_second = url.find("/", ip_dot_start)
                base_url = url[:ip_start_index]  # http:// or https://
                ip_address = url[ip_start_index:ip_index_second]
                url_x = f"{base_url}{ip_address}"

                json_url = f"{url}"
                response = requests.get(json_url, timeout=0.5)
                json_data = response.json()

                try:
                    # è§£æJSONæ–‡ä»¶ï¼Œè·å–nameå’Œurlå­—æ®µ
                    for item in json_data['data']:
                        if isinstance(item, dict):
                            name = item.get('name')
                            urlx = item.get('url')
                            if ',' in urlx:
                                urlx = f"aaaaaaaa"
                            # if 'http' in urlx or 'udp' in urlx or 'rtp' in urlx:
                            if 'http' in urlx:
                                urld = f"{urlx}"
                            else:
                                urld = f"{url_x}{urlx}"

                            if name and urlx:
                                name = get_replace_name(name)
                                _results.append(f"{name},{urld}")
                except:
                    continue
            except:
                continue

    for result in _results:
        line = result.strip()
        if line:
            channel_name, channel_url = line.split(',')
            channels.append((channel_name, channel_url))

    # åˆ›å»ºå¤šä¸ªå·¥ä½œçº¿ç¨‹
    num_threads = 10
    for _ in range(num_threads):
        t = threading.Thread(target=worker, daemon=True)  # å°†å·¥ä½œçº¿ç¨‹è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
        t.start()

    # æ·»åŠ ä¸‹è½½ä»»åŠ¡åˆ°é˜Ÿåˆ—
    for channel in channels:
        task_queue.put(channel)

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    task_queue.join()

    # å¯¹é¢‘é“è¿›è¡Œæ’åº
    results.sort(key=lambda x: (x[0], -float(x[2].split()[0])))
    results.sort(key=lambda x: channel_key(x[0]))

    result_counter = 8  # æ¯ä¸ªé¢‘é“éœ€è¦çš„ä¸ªæ•°
    first_channel_url = results[0][1]
    with open(os.path.join(save_path, "lives.txt"), 'w', encoding='utf-8') as file:
        channel_counters = {}
        file.write('ğŸŒï½œå¤®è§†é¢‘é“,#genre#\n')
        for result in results:
            channel_name, channel_url, speed = result
            if 'CCTV' in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"{channel_name},{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"{channel_name},{channel_url}\n")
                    channel_counters[channel_name] = 1
        channel_counters = {}
        file.write('ğŸ›°ï½œå«è§†é¢‘é“,#genre#\n')
        for result in results:
            channel_name, channel_url, speed = result
            if 'å«è§†' in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"{channel_name},{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"{channel_name},{channel_url}\n")
                    channel_counters[channel_name] = 1
        channel_counters = {}
        file.write('ğŸ‘‘ï½œå…¶ä»–é¢‘é“,#genre#\n')
        for result in results:
            channel_name, channel_url, speed = result
            if 'CCTV' not in channel_name and 'å«è§†' not in channel_name and 'æµ‹è¯•' not in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"{channel_name},{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"{channel_name},{channel_url}\n")
                    channel_counters[channel_name] = 1

        file.write(f'ğŸ“ºï½œå®šæœŸç»´æŠ¤,#genre#\n{formatted_date}æ›´æ–°,{first_channel_url}\n')

    with open(os.path.join(save_path, "lives.m3u"), 'w', encoding='utf-8') as file:
        channel_counters = {}
        file.write('#EXTM3U\n')
        file.write(f"{first_channel_url}\n")
        for result in results:
            channel_name, channel_url, speed = result
            if 'CCTV' in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"#EXTINF:-1 group-title=\"å¤®è§†é¢‘é“\",{channel_name}\n")
                        file.write(f"{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"#EXTINF:-1 group-title=\"å¤®è§†é¢‘é“\",{channel_name}\n")
                    file.write(f"{channel_url}\n")
                    channel_counters[channel_name] = 1
        channel_counters = {}
        # file.write('å«è§†é¢‘é“,#genre#\n')
        for result in results:
            channel_name, channel_url, speed = result
            if 'å«è§†' in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"#EXTINF:-1 group-title=\"å«è§†é¢‘é“\",{channel_name}\n")
                        file.write(f"{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"#EXTINF:-1 group-title=\"å«è§†é¢‘é“\",{channel_name}\n")
                    file.write(f"{channel_url}\n")
                    channel_counters[channel_name] = 1
        channel_counters = {}
        # file.write('å…¶ä»–é¢‘é“,#genre#\n')
        for result in results:
            channel_name, channel_url, speed = result
            if 'CCTV' not in channel_name and 'å«è§†' not in channel_name and 'æµ‹è¯•' not in channel_name:
                if channel_name in channel_counters:
                    if channel_counters[channel_name] >= result_counter:
                        continue
                    else:
                        file.write(f"#EXTINF:-1 group-title=\"å…¶ä»–é¢‘é“\",{channel_name}\n")
                        file.write(f"{channel_url}\n")
                        channel_counters[channel_name] += 1
                else:
                    file.write(f"#EXTINF:-1 group-title=\"å…¶ä»–é¢‘é“\",{channel_name}\n")
                    file.write(f"{channel_url}\n")
                    channel_counters[channel_name] = 1

        file.write(f"#EXTINF:-1 group-title=\"ğŸ“ºï½œå®šæœŸç»´æŠ¤\",{formatted_date}æ›´æ–°\n")

    t2 = time.time()
    print(f'å…±è®¡è€—æ—¶:{round(t2 - t1, 2)}ç§’')


if __name__ == "__main__":
    main()
